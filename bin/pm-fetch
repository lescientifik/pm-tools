#!/usr/bin/env bash
# pm-fetch - Fetch PubMed XML from E-utilities API
# Usage: echo "12345" | pm-fetch > articles.xml

set -euo pipefail

# Source common functions
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
# shellcheck source=lib/pm-common.sh
source "${SCRIPT_DIR}/../lib/pm-common.sh"

# Configuration
EFETCH_URL="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
BATCH_SIZE=200
RATE_LIMIT_DELAY=0.34  # ~3 requests per second

# Read all PMIDs into array
pmid_list=()
while IFS= read -r line || [[ -n "$line" ]]; do
    # Skip empty lines
    [[ -z "$line" ]] && continue
    pmid_list+=("$line")
done

# If no PMIDs, exit cleanly
if [[ ${#pmid_list[@]} -eq 0 ]]; then
    exit 0
fi

# Fetch in batches
batch_num=0
for ((i = 0; i < ${#pmid_list[@]}; i += BATCH_SIZE)); do
    # Rate limiting: wait between requests (except first)
    if ((batch_num > 0)); then
        sleep "$RATE_LIMIT_DELAY"
    fi
    batch_num=$((batch_num + 1))

    # Build comma-separated list for this batch
    batch_pmids=""
    for ((j = i; j < i + BATCH_SIZE && j < ${#pmid_list[@]}; j++)); do
        if [[ -z "$batch_pmids" ]]; then
            batch_pmids="${pmid_list[j]}"
        else
            batch_pmids="${batch_pmids},${pmid_list[j]}"
        fi
    done

    # Fetch this batch
    curl -s "${EFETCH_URL}?db=pubmed&id=${batch_pmids}&rettype=abstract&retmode=xml"
done
